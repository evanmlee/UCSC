{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from pandas.errors import EmptyDataError\n",
    "import re\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "import subprocess\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "import os, os.path\n",
    "import glob\n",
    "import shutil\n",
    "from Bio.SubsMat.MatrixInfo import blosum62\n",
    "import matplotlib.pyplot as plt\n",
    "# from bs4 import BeautifulSoup \n",
    "import xml.etree.ElementTree as ET\n",
    "import urllib\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "#Chrome Driver imports\n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException, NoSuchElementException \n",
    "from selenium.webdriver.support.ui import WebDriverWait # available since 2.4.0\n",
    "from selenium.webdriver.support import expected_conditions as EC # available since 2.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_directory(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "def remove_thing(path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        os.remove(path)\n",
    "\n",
    "def empty_directory(path):\n",
    "    for i in glob.glob(os.path.join(path, '*')):\n",
    "        remove_thing(i)\n",
    "\n",
    "def write_errors(gene_name,message,errors_fpath=\"tmp/errors.tsv\"):\n",
    "    if not os.path.exists(errors_fpath):\n",
    "        errors_f = open(errors_fpath,'wt')\n",
    "        errors_f.write(\"gene\\tmessage\\n\")\n",
    "        errors_f.close()\n",
    "    f_line = \"{0}\\t{1}\\n\".format(gene_name,message)\n",
    "    #Check if f_line already in errors_f\n",
    "    errors_f = open(errors_fpath,'rt')\n",
    "    errors_flines = errors_f.readlines()\n",
    "    if f_line not in errors_flines:\n",
    "        errors_f = open(errors_fpath,'at')\n",
    "        errors_f.write(f_line)\n",
    "        errors_f.close()\n",
    "        \n",
    "create_directory(\"tmp\")\n",
    "empty_directory(\"tmp\")\n",
    "\n",
    "split_parent_dir_path = \"reorganized_data\"\n",
    "create_directory(split_parent_dir_path)\n",
    "split_dir_path = \"reorganized_data/hg38AA\"\n",
    "create_directory(split_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTA_PATH = \"hg38_multiz100way/knownCanonical.exonAA.fa\"\n",
    "TRANSCRIPT_LIST_PATH = \"{0}/hg38_transcripts.txt\".format(split_parent_dir_path)\n",
    "transcript_list_f = open(TRANSCRIPT_LIST_PATH,'at')\n",
    "\n",
    "curr_ts_id = \"@@@\"\n",
    "EOF = False\n",
    "# header_dict,seq_dict = {}, {}\n",
    "block_idx = 0\n",
    "# ts_id_set = set()\n",
    "\n",
    "with open(FASTA_PATH,'rt') as fasta_f: \n",
    "    for i in range(1000000):\n",
    "        if EOF:\n",
    "            break \n",
    "        #Iterate over blocks of 201 lines (200 lines corresponding to alternating UCSC Fasta headers and sequence data)\n",
    "        #Followed by one blank line \n",
    "        for j in range(200):\n",
    "            fline = fasta_f.readline()\n",
    "            if j == 0:\n",
    "                #Set ts_id to be the corresponding Ensembl transcript ID for this fasta block. \n",
    "                try:\n",
    "                    ts_id = re.search(\">(ENST\\d+\\.\\d+)_\",fline).groups()[0]\n",
    "                except: \n",
    "                    #Means extra blank line separating transcripts; read extra line and repeat ts_id extraction\n",
    "                    #Since end of transcript block of lines, can close out_fasta_f\n",
    "#                     out_fasta_f.close()\n",
    "                    fline = fasta_f.readline()\n",
    "                    attempted_match = re.search(\">(ENST\\d+\\.\\d+)_\",fline)\n",
    "                    if attempted_match:\n",
    "                        ts_id = re.search(\">(ENST\\d+\\.\\d+)_\",fline).groups()[0]\n",
    "                    else:\n",
    "                        EOF = True\n",
    "                        ts_id = curr_ts_id\n",
    "#                         skip_ct = 0\n",
    "# #                         while attempted_match is None:\n",
    "# #                             fline = fasta_f.readline()\n",
    "# #                             attempted_match = re.search(\">(ENST\\d+\\.\\d+)_\",fline)\n",
    "# #                             skip_ct+=1\n",
    "#                         print(\"Warning - irregularity in UCSC data, required skipping of {0} lines\".format(skip_ct))\n",
    "#                         print(\"{0}: index of block\".format(i))\n",
    "#                         print(\"{0}: prev ts_id\".format(curr_ts_id))\n",
    "# #                         print(\"{0}: affected ts_id\".format(ts_id))\n",
    "#                         print(fline)\n",
    "#                         ts_id = re.search(\">(ENST\\d+\\.\\d+)_\",fline).groups()[0]                 \n",
    "                out_fasta_fpath = \"{0}/{1}.fasta\".format(split_dir_path,ts_id)\n",
    "                if os.path.exists(out_fasta_fpath):\n",
    "                    for _ in range(199):\n",
    "                        fasta_f.readline()\n",
    "#                     print(\"File exists for transcript value {0}\".format(ts_id))\n",
    "#                     if ts_id not in ts_id_set:\n",
    "#                         ts_id_set.add(ts_id)\n",
    "#                         transcript_list_f.write(ts_id+\"\\n\")\n",
    "                    block_idx = 0\n",
    "                    break\n",
    "                #Start of new transcript block \n",
    "                #1: append transcript_id to transcript list file \n",
    "                #2: reinitialize all variables for merging each block of UCSC multiz into one line \n",
    "                #3: Open new fasta file   \n",
    "                if not ts_id == curr_ts_id or EOF:\n",
    "                    #Below condition ignores first time initializing new transcript block\n",
    "                    #Format and write output at this point (single line seq records, eliminate\n",
    "                    #extraneous information in UCSC headers and keep only transcript/genome name and coordinates)\n",
    "                    if not curr_ts_id == \"@@@\":\n",
    "#                         if curr_ts_id not in ts_id_set:\n",
    "#                             ts_id_set.add(curr_ts_id)\n",
    "                        transcript_list_f.write(curr_ts_id+\"\\n\")\n",
    "                        out_fasta_fpath = \"{0}/{1}.fasta\".format(split_dir_path,curr_ts_id)\n",
    "                        out_fasta_f = open(out_fasta_fpath,'wt')\n",
    "#                         print(curr_ts_id)\n",
    "#                         print(out_fasta_fpath)\n",
    "                        for record_tag in header_dict:\n",
    "                            header_line = header_dict[record_tag]\n",
    "                            seq_line = seq_dict[record_tag]+\"\\n\"\n",
    "                            if record_tag in f_coords_dict:\n",
    "                                f_coords = f_coords_dict[record_tag]\n",
    "                                l_coords = l_coords_dict[record_tag]\n",
    "                                pos_re = \"([\\w\\.]+:)(\\d+)\\-(\\d+)([\\-\\+])\"\n",
    "                                try:\n",
    "                                    chr_,f1,f2,strand = re.search(pos_re,f_coords).groups()\n",
    "                                    _,l1,l2,_ = re.search(pos_re,l_coords).groups()\n",
    "                                    coords_str = \"{0}{1}-{2}{3}\".format(chr_,f1,l2,strand)\n",
    "                                    formatted_header = \"{0} {1}\\n\".format(record_tag,coords_str)\n",
    "                                except:\n",
    "                                    print(\"Reg exp error\")\n",
    "                                    print(f_coords)\n",
    "                                    print(l_coords)\n",
    "                            else:\n",
    "                                #No coords info/ no sequence record. Use record_tag as formatted_header\n",
    "                                formatted_header = \"{0}\\n\".format(record_tag)\n",
    "                            out_fasta_f.write(formatted_header)\n",
    "                            out_fasta_f.write(seq_line)\n",
    "                        out_fasta_f.close()\n",
    "                    if EOF:\n",
    "                        break\n",
    "                    curr_ts_id = ts_id\n",
    "                    block_idx = 0\n",
    "                    header_dict, seq_dict, f_coords_dict, l_coords_dict = {}, {}, {}, {}\n",
    "            #First block: extract number of blocks from header lines (n_blocks), extract record_tag \n",
    "            #(species/ genome) information for each sequence and store 1) first block genome coordinates \n",
    "            #(f_coords) 2) header line information (other info encoded in UCSC fasta headers) and 3) first\n",
    "            #block of sequence data in seq_dict\n",
    "            if block_idx == 0:\n",
    "                if j%2 == 0:\n",
    "                    if j == 0:\n",
    "                        schema_re = re.search(\">ENST\\d+\\.\\d+_[a-zA-Z0-9]+_\\d+_(\\d+) \",fline)\n",
    "                        n_blocks = schema_re.groups()[0]\n",
    "                    record_tag = re.search(\"(>ENST\\d+\\.\\d+_[a-zA-Z0-9]+)_\",fline).groups()[0]\n",
    "                    schema_re = re.search(\">ENST\\d+\\.\\d+_[a-zA-Z0-9]+_\\d+_\\d+ \\d+ \\d \\d ([\\w\\.:\\+\\-]+)\",fline)\n",
    "                    if schema_re: \n",
    "                        #If coordinates provided = UCSC record for that species, store in f_coords_dict\n",
    "                        f_coords = schema_re.groups()[0]\n",
    "                        f_coords_dict[record_tag] = f_coords\n",
    "                        l_coords_dict[record_tag] = f_coords\n",
    "                    header_dict[record_tag] = fline\n",
    "                elif j%2 == 1:\n",
    "                    #even lines = sequence data, store in seq_dict\n",
    "                    seq_dict[record_tag] = fline.strip()\n",
    "            else:\n",
    "                if j%2 == 0:\n",
    "                    #If this block has sequence data for record_tag, update last coordinates \n",
    "                    #Ensures that l_coords_dict has last possible coordinate positions corresponding to record_tag\n",
    "                    record_tag = re.search(\"(>ENST\\d+\\.\\d+_[a-zA-Z0-9]+)_\",fline).groups()[0]\n",
    "                    schema_re = re.search(\">ENST\\d+\\.\\d+_[a-zA-Z0-9]+_\\d+_\\d+ \\d+ \\d \\d ([\\w\\.:\\+\\-]+)\",fline)\n",
    "                    if schema_re: \n",
    "                        l_coords = schema_re.groups()[0]\n",
    "                        l_coords_dict[record_tag] = l_coords\n",
    "                    \n",
    "                elif j%2 == 1:\n",
    "                    #Append block sequence data into entry in seq_dict\n",
    "                    prev_line = seq_dict[record_tag]\n",
    "                    seq_dict[record_tag] = prev_line+fline.strip()\n",
    "#             out_fasta_f.write(fline)\n",
    "        #End of block. Skip blank line delimiting blocks, increment block_idx\n",
    "        fasta_f.readline()\n",
    "        block_idx += 1 \n",
    "transcript_list_f.close()\n",
    "out_fasta_f.close()\n",
    "\n",
    "# print(seq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
